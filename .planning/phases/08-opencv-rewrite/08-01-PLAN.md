---
phase: 08-opencv-rewrite
plan: 01
type: execute
---

<objective>
Replace MediaPipe Face Mesh with OpenCV Haar Cascade classifiers for mouth detection, maintaining all existing features while simplifying dependencies and improving Raspberry Pi compatibility.

Purpose: Eliminate MediaPipe dependency to reduce system complexity, improve ARM compatibility, and achieve faster performance on resource-constrained hardware.
Output: Fully functional mouth detection system using pure OpenCV with Haar cascades, maintaining distance tracking, normalized coordinates, and serial communication.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-opencv-rewrite/DISCOVERY.md
@main.py
@requirements.txt

**Current Implementation:** MediaPipe Face Mesh with 68-point landmark detection
**Target Implementation:** OpenCV Haar Cascade classifiers (face + mouth)

**Key Constraints:**
- Must maintain all existing features: mouth state, distance calculation, normalized coordinates, serial output
- Must be compatible with Raspberry Pi ARM architecture
- Must maintain real-time performance (30fps target)

**Decisions from Discovery:**
- Use Haar Cascade approach for simplicity and performance
- Keep opencv-python (not opencv-contrib-python) to minimize dependencies
- Use mouth bounding box aspect ratio for open/closed detection
- Preserve all visualization and output features
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update requirements.txt and remove MediaPipe</name>
  <files>requirements.txt</files>
  <action>Remove mediapipe>=0.10.0 line from requirements.txt. Keep opencv-python and pyserial. Do NOT add opencv-contrib-python - we're using standard Haar cascades that ship with opencv-python.</action>
  <verify>cat requirements.txt shows only opencv-python and pyserial</verify>
  <done>MediaPipe removed, opencv-python and pyserial remain as only dependencies</done>
</task>

<task type="auto">
  <name>Task 2: Rewrite main.py with Haar Cascade detection</name>
  <files>main.py</files>
  <action>Replace MediaPipe-based detection with OpenCV Haar Cascade approach. Implementation details:

**Face Detection:**
- Use cv2.CascadeClassifier with 'haarcascade_frontalface_default.xml' (ships with OpenCV)
- Detect faces using detectMultiScale with scaleFactor=1.1, minNeighbors=5

**Mouth Detection:**
- Use cv2.CascadeClassifier with 'haarcascade_mcs_mouth.xml' or 'haarcascade_smile.xml' (ships with OpenCV)
- Detect mouth within face ROI (region of interest)
- Calculate mouth bounding box center and dimensions

**Mouth State Detection:**
- Calculate mouth aspect ratio: height / width
- Threshold: ratio > 0.6 = OPEN, ratio <= 0.6 = CLOSED (adjust if needed)
- Alternative: use absolute height threshold similar to current MOUTH_OPEN_THRESHOLD

**Distance Calculation:**
- Keep existing face width approach using face bounding box width instead of landmarks 234/454
- Maintain FOCAL_LENGTH_PX and calibration logic

**Mouth Coordinates (mouthX, mouthY):**
- Calculate mouth center from bounding box: (x + w/2, y + h/2)
- Normalize to [-1, 1] range relative to screen center (existing logic)

**Visualization:**
- Draw rectangle around detected face
- Draw rectangle around detected mouth
- Use same color coding: green for CLOSED, red for OPEN
- Maintain all text overlays (distance, state, face width, normalized coords)

**Serial Communication:**
- Preserve existing serial output format
- Keep optional serial connection with error handling

**What to avoid:**
- Do NOT use opencv-contrib-python or Facemark API - stick to standard Haar cascades
- Do NOT download external model files - use cascades that ship with OpenCV
- Do NOT change the serial output format - Arduino code may depend on it
- Do NOT remove any existing features (distance, coordinates, visualization)

**Error Handling:**
- Handle case where face is detected but mouth is not
- Handle case where no face is detected
- Maintain frame processing even when detection fails
</action>
  <verify>python main.py runs without errors, webcam opens, face and mouth detection works, 'q' key quits</verify>
  <done>Application runs with OpenCV-only detection, no MediaPipe imports, all features functional (mouth state, distance, coordinates, serial, visualization)</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>OpenCV Haar Cascade mouth detection system with all features migrated</what-built>
  <how-to-verify>
    1. Run: python main.py
    2. Verify webcam opens and displays video
    3. Check face detection: green/red rectangle around face
    4. Check mouth detection: rectangle around mouth area
    5. Test mouth open/closed: Open mouth → "MOUTH OPEN" in red, Close mouth → "MOUTH CLOSED" in green
    6. Verify all overlays display: distance, state, face width, mouth coordinates
    7. Check performance: Should run smoothly without lag
    8. Test 'q' key: Should quit cleanly
    9. Optional: If Arduino connected, verify serial messages send correctly
  </how-to-verify>
  <resume-signal>Type "approved" if working correctly, or describe issues (e.g., "mouth detection too sensitive", "performance laggy", "coordinates wrong")</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] requirements.txt contains only opencv-python and pyserial
- [ ] No MediaPipe imports in main.py
- [ ] python main.py runs without import errors
- [ ] Face detection works with Haar cascades
- [ ] Mouth detection works within face region
- [ ] Mouth state detection (OPEN/CLOSED) functions correctly
- [ ] Distance calculation works using face bounding box
- [ ] Normalized coordinates (mouthX, mouthY) calculate correctly
- [ ] Serial communication maintained (if port available)
- [ ] Visual feedback matches previous behavior
- [ ] Performance acceptable for real-time use
</verification>

<success_criteria>

- All MediaPipe dependencies removed
- OpenCV Haar Cascade detection implemented
- Mouth state detection working (OPEN/CLOSED binary classification)
- Distance calculation functional using face width
- Normalized mouth coordinates calculated correctly
- Serial communication preserved
- All visual overlays present and correct
- No functionality regression from MediaPipe version
- Code runs on pure opencv-python without contrib modules
</success_criteria>

<output>
After completion, create `.planning/phases/08-opencv-rewrite/08-01-SUMMARY.md`:

# Phase 8 Plan 1: OpenCV Haar Cascade Migration Summary

**Migrated mouth detection system from MediaPipe to OpenCV Haar Cascades, eliminating external dependencies and improving Raspberry Pi compatibility**

## Accomplishments

- Removed MediaPipe dependency from requirements.txt
- Implemented face detection using haarcascade_frontalface_default
- Implemented mouth detection using haarcascade_mcs_mouth within face ROI
- Migrated mouth state detection to bounding box aspect ratio
- Preserved distance calculation using face bounding box width
- Maintained normalized mouth coordinate calculation
- Kept serial communication functionality intact
- Preserved all visual feedback and overlays

## Files Created/Modified

- `requirements.txt` - Removed mediapipe dependency
- `main.py` - Complete rewrite using OpenCV Haar Cascades

## Decisions Made

- Used Haar Cascade approach over Facemark API for simplicity and performance
- Kept opencv-python instead of opencv-contrib-python to minimize footprint
- Used mouth aspect ratio (height/width) for open/closed detection
- Maintained face width method for distance calculation (using bounding box instead of landmarks)

## Issues Encountered

[Document any issues here, or "None"]

## Next Phase Readiness

- System now uses pure OpenCV with no external face detection dependencies
- Raspberry Pi deployment should be simpler (no MediaPipe ARM compilation)
- Performance may be faster due to simpler cascade classifiers
- If accuracy is insufficient, can migrate to Facemark API in future phase
- Phase 4 (Raspberry Pi Optimization) can now proceed with OpenCV-only stack

</output>
